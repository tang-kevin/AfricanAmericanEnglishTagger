
# Habitual Be Classification with Transformer Model

This project leverages Fairseq and a Transformer model to classify sentences as **habitual be** (+1) or **non-habitual be** (-1). The `fq_transformer_wu.py` script is used for training the model using 10 fold cross validation, while `evaluate_binary.py` generates evaluation metrics for the trained model's classification results for each of the 10 folds. The model files for each fold are generated by the fq_transformer_wu.py code.

## Requirements

Ensure the following modules are loaded:

- `fairseq/0.12.2`
- `python`
- `sklearn`

## Directory Structure

All data files are located in the `/Data/habitual_be/` directory. 

`Kfold_data_habitualbe_sentences` - contains all 10 folds and the sentences that are being tagged

`transform` - contains the feature input (derived from the sentences in kfold_data_habitualbe_sentences folder) used by the transformer for training and inferencing.



## Training and Classification

`python fq_transformer_wu.py /Data/habitual_be/transform/`


## Running Evaluation

`python evaluate_binary.py /Data/habitual_be/transform`
