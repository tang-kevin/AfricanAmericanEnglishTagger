{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d24cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Alice/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import csv\n",
    "import shutil\n",
    "import copy\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from spacy import lookups\n",
    "from spacy import tokenizer\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "from nltk.stem import WordNetLemmatizer as wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import gensim.models\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6776f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import csv\n",
    "import spacy\n",
    "from spacy import lookups\n",
    "from spacy import tokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267f5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training data \n",
    "allData = pd.read_csv(\"MN_48_152_2 19 2024 .txt\", delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d8af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing and adds speaker column\n",
    "speakers = []\n",
    "for i in range(len(allData)):\n",
    "    if (':' in allData.iloc[i, 0]):\n",
    "        index = allData.iloc[i, 0].index(':')\n",
    "        speakers.append((allData.iloc[i, 0])[:index+1])\n",
    "        allData.iloc[i, 0] = re.sub(\"[a-zA-Z]:\\s+\", \"\", allData.iloc[i, 0]) \n",
    "    else:\n",
    "        speakers.append('F:')\n",
    "    allData.iloc[i, 0] = re.sub(\"[a-zA-Z]:\\s+\", \"\", allData.iloc[i, 0])\n",
    "allData.insert (0, \"speaker\", speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2858c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "# Creates a Sentence object\n",
    "# text = text of Sentence\n",
    "# multi = which occurence of negation is being looked at in the sentence\n",
    "  # eg. if the variable be is set to 2, the model will observe whether the 2nd negator is part of a multiple negator\n",
    "    # pair in the sentence\n",
    "# num = the index of the Sentence in the original csv\n",
    "    multNeg = 0\n",
    "    r1 = 0; r2 = 0;\n",
    "    def __init__(self, text, multi, num, true):\n",
    "        self.text = text\n",
    "        self.num = num\n",
    "        self.multi = multi\n",
    "        self.true = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381b4226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    }
   ],
   "source": [
    "# Preproccesses training text for linguistic analysis\n",
    "\n",
    "lines = []\n",
    "\n",
    "with open(\"MN_48_152_2 19 2024 .txt\", \"r\", encoding=\"utf-8\") as tsv_file: #these files are tab separated but you can easily change this to CSV\n",
    "    tsv_reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    header = next(tsv_reader)\n",
    "    for row in tsv_reader:\n",
    "        row = row[:1]\n",
    "        row[0] = re.sub(\"[a-zA-Z]:\\s+\", \"\", row[0]) #removes the interviewer tag\n",
    "        row[0] = re.sub(\"\\s{2,}\", \" \", row[0]) #removes excessive spaces\n",
    "        row[0] = re.sub(\"’|‘\", \"'\", row[0]) #fixes apostrophes\n",
    "        row[0] = re.sub(\"—\", \"--\", row[0]) #m-dash was causing formatting issues, changed it to two dashes\n",
    "        row[0] = re.sub(\"“\", '\"', row[0]) #fixes quotation marks    \n",
    "        lines.append(row[0])\n",
    "         \n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ef91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets list of negators\n",
    "negatives = [\"no\", \"nothing\", \"never\", \"nobody\", \"nowhere\", \"neither\", \"n't\", \"n’t\", \"not\", \"nor\", \"none\", \"nothin’\",\"nothin'\", \"ain’t\", \"ain't\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157a9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of Sentence objects with at least one negator\n",
    "\n",
    "sen = []\n",
    "for line in range(len(lines)):\n",
    "        multi = 1\n",
    "        numNeg = 0\n",
    "        parsed = nlp(lines[line])\n",
    "        for i, word in enumerate(parsed):\n",
    "            if (word.text.lower() in negatives):\n",
    "                numNeg += 1\n",
    "        if (numNeg == 1):\n",
    "            sen.append(Sentence(lines[line], multi, line, 0))\n",
    "        elif (numNeg > 1):\n",
    "            sen.append(Sentence(lines[line], multi, line, 1))\n",
    "        while (numNeg > 1):\n",
    "            multi += 1\n",
    "            sen.append(Sentence(lines[line], multi, line, 1))\n",
    "            numNeg -= 1\n",
    "for Sent in range(len(sen)):\n",
    "    sen[Sent].text = (sen[Sent].text).replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2709fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creates empty arrays corresponding to the parts of speech of the words including and surrounding 'be'\n",
    "# E.g. w = word, p = previous, pp = preprevious, a = after, pa = postafter, etc\n",
    "\n",
    "w = []\n",
    "ppp = []\n",
    "pp = []\n",
    "p = []\n",
    "a = []\n",
    "pa = []\n",
    "ppa = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95ac685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Now; you're not getting no spanking now.\n",
      "2\n",
      "Now; you're not getting no spanking now.\n",
      "3\n",
      "No you can't mess up anything.\n",
      "3\n",
      "No you can't mess up anything.\n",
      "2\n",
      "I've been all up there over there but I ain't been nowhere in Florida.\n",
      "2\n",
      "I've been all up there over there but I ain't been nowhere in Florida.\n",
      "5\n",
      "But these children; if they get to schooling; they won't have to work in nobody's field.\n",
      "5\n",
      "But these children; if they get to schooling; they won't have to work in nobody's field.\n",
      "2\n",
      "Didn't have no radio home.\n",
      "2\n",
      "Didn't have no radio home.\n",
      "1\n",
      "I don't never want to see you like that.\n",
      "1\n",
      "I don't never want to see you like that.\n",
      "1\n",
      "But that wasn't nothing for me to think that he was doing that to me; because of the black or white thing.\n",
      "1\n",
      "But that wasn't nothing for me to think that he was doing that to me; because of the black or white thing.\n",
      "1\n",
      "But I would tell them to trust in God; be sure to trust in God; don't never forget wherever you go to make sure that you put your trust in God and to do the Word .\n",
      "1\n",
      "But I would tell them to trust in God; be sure to trust in God; don't never forget wherever you go to make sure that you put your trust in God and to do the Word .\n",
      "4\n",
      "My daddy wouldn't whip you for nothing.\n",
      "4\n",
      "My daddy wouldn't whip you for nothing.\n",
      "5\n",
      "We get through sell this; I am not going to work on nobody's field.\n",
      "5\n",
      "We get through sell this; I am not going to work on nobody's field.\n",
      "1\n",
      "Okay now we coming down the hill up this way where _________ house wasn't none of them down there except the Guildcreases then the Burnietts.\n",
      "1\n",
      "Okay now we coming down the hill up this way where _________ house wasn't none of them down there except the Guildcreases then the Burnietts.\n",
      "3\n",
      "And we stayed separated- I mean; I divorced her right after then because after she had me put in jail; I knew it wasn't gon be no more of that.\n",
      "3\n",
      "And we stayed separated- I mean; I divorced her right after then because after she had me put in jail; I knew it wasn't gon be no more of that.\n",
      "2\n",
      "I don't know nothing about that.\n",
      "2\n",
      "I don't know nothing about that.\n",
      "1\n",
      "No; wasn't no bicycles.\n",
      "1\n",
      "No; wasn't no bicycles.\n",
      "8\n",
      "It happened because of the dude; somebody is going to die cause I'm not going to be able to communicate with nobody with a microphone.\n",
      "8\n",
      "It happened because of the dude; somebody is going to die cause I'm not going to be able to communicate with nobody with a microphone.\n",
      "1\n",
      "Wasn't nothing on that side but the railroad just like it is now until we got right over there and Missus Duck and her son Sonny Lee up there.\n",
      "1\n",
      "Wasn't nothing on that side but the railroad just like it is now until we got right over there and Missus Duck and her son Sonny Lee up there.\n",
      "2\n",
      "Nobody couldn't wait for me to get up and say because they were going to make fun of me.\n",
      "2\n",
      "Nobody couldn't wait for me to get up and say because they were going to make fun of me.\n",
      "2\n",
      "I didn't want no more of that.\n",
      "2\n",
      "I didn't want no more of that.\n",
      "2\n",
      "We didn't have no tobacco.\n",
      "2\n",
      "We didn't have no tobacco.\n",
      "1\n",
      "I wasn't no midwife , now.\n",
      "1\n",
      "I wasn't no midwife , now.\n",
      "2\n",
      "You ain't got nothing at home you can do?\n",
      "2\n",
      "You ain't got nothing at home you can do?\n",
      "4\n",
      "And I said; if I have to go through that; I don't want to play no more football.\n",
      "4\n",
      "And I said; if I have to go through that; I don't want to play no more football.\n",
      "2\n",
      "But we didn't have no ride.\n",
      "2\n",
      "But we didn't have no ride.\n",
      "2\n",
      "The things that we had to do; we didn't have no swimming pool.\n",
      "2\n",
      "The things that we had to do; we didn't have no swimming pool.\n",
      "1\n",
      "Ain't nothing I can prove now; it's just what I heard.\n",
      "1\n",
      "Ain't nothing I can prove now; it's just what I heard.\n",
      "2\n",
      "I don't know nothing about that.\n",
      "2\n",
      "I don't know nothing about that.\n",
      "2\n",
      "But we didn't have no ride.\n",
      "2\n",
      "But we didn't have no ride.\n",
      "4\n",
      "And I remember getting a present from every teacher in school; and I remember I didn't have to buy no invitations.\n",
      "4\n",
      "And I remember getting a present from every teacher in school; and I remember I didn't have to buy no invitations.\n",
      "4\n",
      "I wasn't going to eat nobody else's cooking.\n",
      "4\n",
      "I wasn't going to eat nobody else's cooking.\n",
      "4\n",
      "I wasn't going to eat nobody else's cooking.\n",
      "4\n",
      "I wasn't going to eat nobody else's cooking.\n",
      "1\n",
      "But ain't nobody; believe it or not; is a kin of her except Rally Johnson.\n",
      "1\n",
      "But ain't nobody; believe it or not; is a kin of her except Rally Johnson.\n",
      "1\n",
      "Ain't nothing I can prove now; it's just what I heard.\n",
      "1\n",
      "Ain't nothing I can prove now; it's just what I heard.\n",
      "2\n",
      "No; it ain't there no more.\n",
      "2\n",
      "No; it ain't there no more.\n",
      "7\n",
      "I laid down on the ground; and when I turned around; I said; I am not going to put my hands on no more tobacco.\n",
      "7\n",
      "I laid down on the ground; and when I turned around; I said; I am not going to put my hands on no more tobacco.\n",
      "2\n",
      "Mister Hart wouldn't cheat nothing.\n",
      "2\n",
      "Mister Hart wouldn't cheat nothing.\n",
      "2\n",
      "And I don't remember no kind of bad stuff.\n",
      "2\n",
      "And I don't remember no kind of bad stuff.\n",
      "3\n",
      "So we were didn't want for nothing.\n",
      "3\n",
      "So we were didn't want for nothing.\n",
      "2\n",
      "you couldn't get nothing but second hand stuff.\n",
      "2\n",
      "you couldn't get nothing but second hand stuff.\n",
      "2\n",
      "I said I only go to church; I don't go no place.\n",
      "2\n",
      "I said I only go to church; I don't go no place.\n"
     ]
    }
   ],
   "source": [
    "# Tags the Sentence objects with each rule\n",
    "\n",
    "index = -1\n",
    "senNum = 1\n",
    "numNeg = 0\n",
    "negIndices = []\n",
    "\n",
    "for Sentence in sen:\n",
    "    index += 1 \n",
    "    numNeg = 0\n",
    "    if (index > 0 and (sen[index].text == sen[index-1].text) and (sen[index].num == sen[index-1].num)):\n",
    "        senNum += 1\n",
    "    else:\n",
    "        senNum = 1\n",
    "    parsed = nlp(Sentence.text)\n",
    "# Find an instance of negation\n",
    "    for i, word in enumerate(parsed):\n",
    "        if (i >= 0 and (word.text.lower() in negatives) and Sentence.true == 1 and Sentence.multNeg != 1):\n",
    "            numNeg += 1\n",
    "            if (numNeg == senNum):\n",
    "                w.append(word.pos_)\n",
    "                negIndices.append(i)\n",
    "                negChildren = list(word.children)\n",
    "                if(word.head == word):\n",
    "                    negSibling = []\n",
    "                else:\n",
    "                    negSibling = list(word.head.children)\n",
    "                negDep = word.dep_\n",
    "                negPOS = word.pos_\n",
    "                negIndex = i\n",
    "                num = 1\n",
    "                next = None\n",
    "                prev = None\n",
    "# Progress through the sentences forwards, if another instance of negation is found within the clause, tag sentence with rule 1 and set multNeg to 1\n",
    "                while ((i+num < len(parsed)) and (num < 9) and (parsed[i+num].pos_ != \"PUNCT\" and parsed[i+num].pos_ != \"CCONJ\" and parsed[i+num].pos_ != \"SCONJ\" and parsed[i+num].text != \"–\")):# and (parsed[i+num].pos_ != 'PRON' and parsed[i+num].pos_ != 'PROP' and parsed[i+num].pos_ != 'NOUN') or parsed[i+num].text in negatives)): \n",
    "                    next = parsed[i+num]\n",
    "                    if next.text.lower() in negatives and (word.text.lower() != \"no\" or next.text.lower() != \"no\"):\n",
    "                        Sentence.r1 = 1\n",
    "                        Sentence.multNeg = 1\n",
    "                        print(num)\n",
    "                        print(Sentence.text)\n",
    "                    num += 1\n",
    "                if (Sentence.r1 != 1):\n",
    "                    Sentence.r1 = 0\n",
    "                num = 1\n",
    "# Progress through the sentences backwards, if another instance of negation is found within the clause, tag sentence with rule 2 and set multNeg to 1\n",
    "                while ((i-num >= 0) and (num < 9) and (parsed[i-num].pos_ != \"PUNCT\") and parsed[i-num].pos_ != \"CCONJ\" and parsed[i-num].pos_ != \"SCONJ\" and parsed[i-num].text != \"–\"):# and ((parsed[i-num].pos_ != 'PRON' and parsed[i-num].pos_ != 'PROP' and parsed[i-num].pos_ != 'NOUN') or parsed[i-num].text in negatives): \n",
    "                    prev = parsed[i-num]\n",
    "                    if prev.text.lower() in negatives and (word.text.lower() != \"no\" or prev.text.lower() != \"no\"):\n",
    "                        Sentence.r2 = 1\n",
    "                        Sentence.multNeg = 1\n",
    "                        print(num)\n",
    "                        print(Sentence.text)\n",
    "                    num += 1\n",
    "                if (Sentence.r2 != 1):\n",
    "                    Sentence.r2 = 0\n",
    "# If neither rule 1 or rule 2 apply, set Sentence.multNeg to 0 to indicate the lack of multiple negation\n",
    "                if (Sentence.r1 !=1 and Sentence.r2 != 1):\n",
    "                    Sentence.multNeg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83e0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation pna values of duplicated sentences\n",
    "# e.g. if any have multiple negation, assign all mult neg values to 1, else keep them as 0\n",
    "\n",
    "testError = []\n",
    "multNeginSentence = []\n",
    "\n",
    "for i in range(len(sen)-1):\n",
    "    if (i < len(sen)-1):\n",
    "        j = i+1 \n",
    "        if (sen[i].text != sen[j].text):\n",
    "            if (sen[i].multNeg == 1):\n",
    "                multNeginSentence.append(True)\n",
    "            else:\n",
    "                multNeginSentence.append(False)\n",
    "        while (sen[i].text == sen[j].text):\n",
    "            if (sen[i].multNeg == 1 or sen[j].multNeg) == 1:\n",
    "                multNeginSentence.append(True)\n",
    "            else:\n",
    "                multNeginSentence.append(False)\n",
    "            if (sen[j].multNeg == 1):\n",
    "                sen[i].multNeg == sen[j].multNeg\n",
    "            if (sen[i].multNeg == 1):\n",
    "                sen[j].multNeg == sen[i].multNeg\n",
    "            testError.append((j, sen[j]))\n",
    "            if (j < len(sen)-1):\n",
    "                j +=1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "if len(multNeginSentence) != len(sen):\n",
    "    if (sen[-1].multNeg == 1):\n",
    "        multNeginSentence.append(True)\n",
    "    else:\n",
    "        multNeginSentence.append(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6cd2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "# Goes back to the original data and annotates each sentences with multiple negation\n",
    "\n",
    "multNeg = []\n",
    "for i in range(len(allData)):\n",
    "    m = 0\n",
    "    for j in range(len(sen)):\n",
    "        if i == sen[j].num:\n",
    "            if (m != 1):\n",
    "                m = sen[j].multNeg\n",
    "            if (m == 1 and (\"%MN\" not in allData.loc[i, 'speaker'])):\n",
    "                allData.loc[i, 'speaker'] = allData.loc[i, 'speaker'] + \" %MN\"\n",
    "    multNeg.append(m)\n",
    "print(len(multNeg))\n",
    "print(len(allData))\n",
    "allData['Multiple Negators'] = multNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c6eef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   agreement       1.00      0.99      1.00       117\n",
      "disagreement       0.97      1.00      0.99        38\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.99      1.00      0.99       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "\n",
    "predictions = allData['Multiple Negators']\n",
    "y = allData['Multiple Negation']\n",
    "target_names = ['agreement', 'disagreement']\n",
    "print(classification_report(y, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94fc08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write annotations to txt file\n",
    "\n",
    "with open('multNeg.txt', 'w+', newline='') as file:\n",
    "   allData.to_csv('multNeg.txt', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
